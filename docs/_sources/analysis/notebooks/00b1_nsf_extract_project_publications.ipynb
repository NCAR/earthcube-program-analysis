{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d85963-b9d7-47f1-96cc-00d06c763b10",
   "metadata": {},
   "source": [
    "# Extract NSF Project Publications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc28cdb-1fdb-41e5-b5f8-331868a6c337",
   "metadata": {},
   "source": [
    "This notebook uses the helper module [`crossref`](./crossref.py) to use the necessary functions to grab citation metadata including **citation counts**, which are used in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe10db4-5d70-4b9c-a275-84ca8cb0a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crossref import get_metadata, get_doi, get_doi_bib_lookup, get_bib_citation\n",
    "import time\n",
    "\n",
    "BE_NICE = .60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9688b0d-9764-4e44-938b-20cb09751bf7",
   "metadata": {},
   "source": [
    "# can be deleted\n",
    "\n",
    "def get_doi(doi_like):\n",
    "    import re\n",
    "    pattern = r\".*(10\\.\\d+\\/.*)\"\n",
    "    m = re.match(pattern, doi_like)\n",
    "    if m:\n",
    "        return m[1]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def get_doi_bib_lookup(citation):\n",
    "    import requests\n",
    "    import re\n",
    "    \n",
    "    r = requests.get(f\"https://api.crossref.org/works?query.bibliographic={citation.strip()}\")\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        resp = r.json()\n",
    "        # assigned first item to hit\n",
    "        hit = resp['message']['items'][0]\n",
    "\n",
    "        t1 = re.sub(r'[,.:]', ' ', citation.split('~')[1]).lower().split()\n",
    "        t2 = re.sub(r'[,.:]', ' ', hit['title'][0]).lower().split()\n",
    "\n",
    "        if not set(t2)-set(t1):\n",
    "            return hit['DOI'], hit['is-referenced-by-count'], hit        \n",
    "        else:\n",
    "            return None, None, None\n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "def get_bib_citation(doi):\n",
    "    import requests\n",
    "    header = { \"Accept\": \"text/x-bibliography; style=american-meteorological-society\" }\n",
    "    r = requests.get(f\"https://doi.org/{doi}\", headers=header)\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        return(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c034fb7-cbf8-4f6e-99b1-040d171606fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NSF EXTRACTION\n",
    "\n",
    "Now that we have the appropriate code to get citations and validate DOIs, we can being the data extraction from NSF.\n",
    "\n",
    "This will require the [NSF Awards API]() and in the following computation, we will extract **ONLY the DOIs** found in the NSF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7b8c45-0e31-45e2-a579-1ec95add7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fb2ff1-22ce-40ca-8136-5634d8e73c58",
   "metadata": {},
   "source": [
    "### LOAD NSF AWARDS DATA DUMP FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f169a58-5f25-4d6c-8ede-2768a701180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsf_json = json.load(\n",
    "    open(\"../outputs/nsf/data_full_dump.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a56041-c5b0-4e1e-81a8-1dfab601a21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nsf_json.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e63de7-5bdb-44cc-9e0c-77f6b915cf24",
   "metadata": {},
   "source": [
    "* 215 TOTAL PROJECTS (UNIQUE AWARD IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff292d-7cb3-47ab-99e0-494aa402f602",
   "metadata": {},
   "source": [
    "### BUILD ID -> PUBLICATION MAPPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4faa4d4-390d-4ce1-8735-4d70c3219102",
   "metadata": {},
   "source": [
    "Now that we have verified the Award ID count checks out, we will search the NSF data for publications.  We will notice that the dataset includes two keys `publicationResearch` and `publicationConference` which contain the list of publications in similar form to:\n",
    "\n",
    "```\n",
    "Hsu, L., B. McElroy, R.L. Martin, W. Kim~Building a Sediment Experimentalist Network (SEN): sharing best practices for experimental methods and data management~The Sedimentary Record~11~2013~9~~doi:10.2110/sedred.2013.4~0~ ~0~ ~03/02/2022 04:30:09.530000000\n",
    "```\n",
    "\n",
    "It will be noted the `~` seperate fields and field 8 contains the DOI (if it exists at all).  \n",
    "\n",
    "* A first pass will extract DOIs that exist and look them up directly. \n",
    "* A second pass will perform a **freetext lookup on the title and authors** in subsequent cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461e4fc6-aade-41ef-a31d-dc7db1321f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................................................................................................................................................................................................................................................................................................................................................................CPU times: total: 0 ns\n",
      "Wall time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'''\n",
    "NOTE THIS CELL WILL TAKE TIME TO EXECUTE AS IT WILL LOOKUP \n",
    "ALL DOIS FOUND IN THE NSF DATA PAYLOAD.  TYPICAL RUNTIMES\n",
    "VARY BUT EXPECT BETWEEN 8 AND 15 MINUTES.\n",
    "'''\n",
    "id_map = {}\n",
    "\n",
    "for nsfid in nsf_json.keys():\n",
    "    data = nsf_json[nsfid]\n",
    "    \n",
    "    if data.get('publicationResearch'):\n",
    "        for p in data['publicationResearch']:\n",
    "            if id_map.get(nsfid):\n",
    "                id_map[nsfid].extend(\n",
    "                [\n",
    "                    {'citation': p, \n",
    "                     'doi': get_doi(p.split('~')[7])\n",
    "                    } \n",
    "                ])\n",
    "            else:\n",
    "                id_map[nsfid] = [\n",
    "                    {'citation': p, \n",
    "                     'doi': get_doi(p.split('~')[7])\n",
    "                    } \n",
    "                ]\n",
    "            print(\".\", end=\"\")\n",
    "\n",
    "    if data.get('publicationConference'):\n",
    "        for p in data['publicationConference']:\n",
    "            if id_map.get(nsfid):\n",
    "                id_map[nsfid].extend(\n",
    "                [\n",
    "                    {'citation': p, \n",
    "                     'doi': get_doi(p.split('~')[7])\n",
    "                    } \n",
    "                ])\n",
    "            else:\n",
    "                id_map[nsfid] = [\n",
    "                    {'citation': p, \n",
    "                     'doi': get_doi(p.split('~')[7])\n",
    "                    } \n",
    "                ]\n",
    "            print(\".\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7fe68d-f432-4d5b-9543-718d94743d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1324760', '1340233', '1340265', '1340301', '1343760', '1343785', '1343800', '1343802', '1343811', '1343813', '1354693', '1440133', '1440081', '1440084', '1440109', '1440116', '1440139', '1440195', '1440202', '1440312', '1440293', '1440181', '1440213', '1440294', '1440315', '1440333', '1440323', '1440291', '1440332', '1440327', '1440351', '1540966', '1540979', '1541002', '1541015', '1541008', '1540849', '1541036', '1541029', '1540996', '1541039', '1540998', '1541049', '1541043', '1540542', '1541047', '1540938', '1541044', '1541057', '1541007', '1541010', '1661918', '1541390', '1542058', '1632211', '1639588', '1639614', '1639683', '1639698', '1639707', '1639714', '1639734', '1639749', '1639710', '1639716', '1639738', '1639748', '1639759', '1639547', '1639696', '1639764', '1639557', '1639775', '1740595', '1740581', '1740648', '1740693', '1740694', '1740704', '1740627', '1743321', '1927578', '1928288', '1928369', '1928315', '1928305', '1928389', '1928403', '1928406', '2026932', '2026933', '2026951', '2126315', '2125974', '2126474', '2126449'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "260d1468-f6ae-4f74-ac11-e0523cce74a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'citation': \"Xie, Yiqun and Jia, Xiaowei and Bao, Han and Zhou, Xun and Yu, Jia and Ghosh, Rahul and Ravirathinam, Praveen~Spatial-Net: A Self-Adaptive and Model-Agnostic Deep Learning Framework for Spatially Heterogeneous Datasets~Proceedings of the 29th International Conference on Advances in Geographic Information Systems (SIGSPATIAL'21)~~2021~~~https://doi.org/10.1145/3474717.3483970~10329517~313 to 323~10329517~OSTI~11/08/2022 21:03:23.293000000\",\n",
       "  'doi': '10.1145/3474717.3483970'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_map['2126449']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f8fbe-b270-4e6c-8902-3a3a40b73ec9",
   "metadata": {},
   "source": [
    "## JSON FILE CREATION\n",
    "Once we have the data, we will improve it by including the citation counts from the crossref using their [content negotiation](https://citation.crosscite.org/docs.html) code as well as the crossref metadata.  \n",
    "\n",
    "Ultimately, the output file ([outputs/nsf/nsf_mapping.json](outputs/nsf/nsf_mapping.json)) will be **the definitive source** for an individual run.\n",
    "\n",
    "The sample below shows the format of the mapping file, where each key contains the NSF ID and the value being a list of found publications which include the original NSF citation (the \"source\" citation), the DOI the crossref citations, the crossref metadata (the \"source\" metadata) and the formatted AMS citation.  The allows some auditing with the source, as well as the rapid retrieval of citation counts and styled / formatted citation.\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"1324760\": [\n",
    "        {\n",
    "            \"citation\": \"Hsu, L., R. Martin, B. McElroy, W. Kim~Data management, sharing, and reuse in experimental geomorphology: challenges, strategies, and scientific opportunities.~Geomorphology~244~2015~180~~~0~ ~0~ ~29/01/2019 18:06:33.923000000\",\n",
    "            \"doi\": \"10.1016/j.geomorph.2015.03.039\",\n",
    "            \"cites\": 19,\n",
    "            \"cr_meta\": { ... \n",
    "            },\n",
    "            \"ams_bib\": \"Hsu, L., R. L. Martin, B. McElroy, K. Litwin-Miller, and W. Kim, 2015: Data management, sharing, and reuse in experimental geomorphology: Challenges, strategies, and scientific opportunities. Geomorphology, 244, 180\\u2013189, https://doi.org/10.1016/j.geomorph.2015.03.039.\\n\"\n",
    "        }, \n",
    "        ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91034a22-c7ac-4ef4-9970-b1964837d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......X.....XXX..X........X.XX.XX.......XX....XXX....XX\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Meng, H., Kommineni, R., Pham, Q., Gardner, R., Malik, T., & Thain, D.~An invariant framework for conducting reproducible computational science.~Journal of Computational Science~9~2015~137~~~0~ ~0~ ~03/02/2022 04:30:09.53000000\n",
      "X...X.X..\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Regalia, B., Janowicz, K., & Gao, S.~VOLT: A Provenance-Producing, Transparent SPARQL Proxy for the On-Demand Computation of Linked Data and its Application to Spatiotemporally Dependent Data.~ESWC: Extended Semantic Web Conference 201~~2016~~~~0~ ~0~ ~01/09/2016 15:06:21.460000000\n",
      "X....\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Vardeman II, C. F., Krisnadhi, A. A., Cheatham, M., Janowicz, K., Ferguson, H., Hitzler, P., & Buccellato, A. P.~An Ontology Design Pattern and Its Use Case for Modeling Material Transformation~Semantic Web~~2016~~~~0~ ~0~ ~13/09/2017 04:51:26.273000000\n",
      "X\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Blomqvist, E., Hitzler, P., Janowicz, K., Krisnadhi, A., Narock, T., & Solanki, M.~Considerations regarding ontology design patterns~Semantic Web~7~2016~~~~0~ ~0~ ~01/09/2016 15:06:21.450000000\n",
      "X\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Blomqvist, E., Hitzler, P., Janowicz, K., Krisnadhi, A., Narock, T., & Solanki, M.~Considerations regarding ontology design patterns~Semantic Web Journal~7~2016~1~~~0~ ~0~ ~01/09/2016 10:48:28.573000000\n",
      "X.\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: A. Krisnadhi, Hu, Y., Janowicz, K., Hitzler, P., Arko, R., Carbotte, S., Chandler, C., Cheatham, M., Fils, D., Finin, T., Ji, P., Jones, M., Karima, N., Lehnert, K., Mickle, A., Narock, T., O'Brien, M., Raymond, L., Shepherd, A., Schildhauer, M., and Wieb~The GeoLink Framework for Pattern-based Linked Data Integration~ISWC 2015 Posters & Demonstrations Track co-located with the 14th International Semantic Web Conference (ISWC-2015), Bethlehem, PA, USA, October 11, 2015~~2015~~~~0~ ~0~ ~31/08/2016 09:17:49.423000000\n",
      "XX\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Blomqvist, E., Hitzler, P., Janowicz, K., Krisnadhi, A., Narock, T., & Solanki, M.~Considerations regarding ontology design patterns~Semantic Web~7~2016~~~~0~ ~0~ ~31/08/2016 09:17:49.440000000\n",
      "XXXXXXX\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Vardeman II, C. F., Krisnadhi, A. A., Cheatham, M., Janowicz, K., Ferguson, H., Hitzler, P., & Buccellato, A. P.~An Ontology Design Pattern and Its Use Case for Modeling Material Transformation~Semantic Web~~2017~~~~0~ ~0~ ~29/11/2017 09:39:47.430000000\n",
      "XXX........\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Mayernik, M.S., Gross, M.B., Corson-Rikert, J., Daniels, M.D., Johns, E.M., Khan, H., Maull, K., Rowan, L.R., & Stott, D.~Building geoscience Semantic Web applications using established ontologies~Data Science Journal.~~2016~~~~0~ ~0~ ~19/07/2017 17:01:27.720000000\n",
      "X......\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Sun, Z., Fang, H., Di, L. and Yue, P~Realizing Parameterless Automatic Classification of Remote Sensing Imagery Using Ontology Engineering and Cyberinfrastructure Techniques.~Computers & Geosciences.~94~2016~56~~j.cageo.2016.06.004~0~ ~0~ ~08/09/2016 16:14:52.760000000\n",
      "X.X\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Tan, X., Di, L., Deng, M., Huang, F., Ye, X., Sha, Z., Sun, Z., Gong, W., Shao, Y. and Huang~Agent-as-a-service-based geospatial service aggregation in the cloud: A case study of flood response~Environmental Modelling & Software~84~2016~210~~~0~ ~0~ ~17/01/2018 17:01:22.596000000\n",
      "X..\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Sun, Z., Fang, H., Di, L. and Yue, P.,~Realizing Parameterless Automatic Classification of Remote Sensing Imagery Using Ontology Engineering and Cyberinfrastructure Techniques~Computers & Geosciences~94~2016~56~~~0~ ~0~ ~17/01/2018 17:01:22.570000000\n",
      "X.........XXX...X............X......X.......\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: L. Leonard and C. Duffy~Visualization workflows for level-12 HUC scales: Towards an expert system for watershed analysis in a distributed computing environment~Environmental Modelling & Software~78~2016~163~~~0~ ~0~ ~08/09/2016 09:43:24.40000000\n",
      "XX.......\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Smith II, P. L., Malik, T., & Berg-Cross, G.~Rediscovering Earthcube: Collaborate. Or Collaborate Not. There Is No I.~OCLC Systems & Services: International Digital Library Perspectives (Oss:Idlp)~32~2015~~~~0~ ~0~ ~20/07/2016 02:20:25.390000000\n",
      "X.............X..XX.................XX.XX.\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Xia, J., Yang, C., Liu, K., Gui, Z., Li, Z., Huang, Q., & Li, R.~Adopting cloud computing to optimize spatial web portals for better performance to support Digital Earth and other global geospatial initiatives.~International Journal of Digital Earth~8~2015~451~~~0~ ~0~ ~18/10/2018 14:56:43.200000000\n",
      "X........\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Xia, J., Yang, C., Liu, K., Gui, Z., Li, Z., Huang, Q., & Li, R.~Adopting cloud computing to optimize spatial web portals for better performance to support Digital Earth and other global geospatial initiatives~International Journal of Digital Earth~~2015~451~~~0~ ~0~ ~18/08/2017 15:36:19.870000000\n",
      "X..\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Xia, J., Yang, C., Liu, K., Gui, Z., Li, Z., Huang, Q., & Li, R.~Adopting cloud computing to optimize spatial web portals for better performance to support Digital Earth and other global geospatial initiatives.~International Journal of Digital Earth~8~2015~451~~~0~ ~0~ ~29/07/2016 18:18:45.600000000\n",
      "X....\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Xia, J., Yang, C., Liu, K., Gui, Z., Li, Z., Huang, Q., & Li, R.~Adopting cloud computing to optimize spatial web portals for better performance to support Digital Earth and other global geospatial initiatives~International Journal of Digital Earth~~2015~~~~0~ ~0~ ~24/08/2017 16:44:58.943000000\n",
      "X..\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Xia, J., Yang, C., Liu, K., Gui, Z., Li, Z., Huang, Q., & Li, R.~Adopting cloud computing to optimize spatial web portals for better performance to support Digital Earth and other global geospatial initiatives~Journal of Digital Earth~8~2015~451~~~0~ ~0~ ~28/07/2016 18:41:21.283000000\n",
      "X\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: ?\tXia, J., Yang, C., Liu, K., Gui, Z., Li, Z., Huang, Q., & Li, R.~Adopting cloud computing to optimize spatial web portals for better performance to support Digital Earth and other global geospatial initiatives~International Journal of Digital Earth~8~2015~451~~~0~ ~0~ ~23/08/2017 18:05:35.496000000\n",
      "X\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Xia, J., Yang, C., Liu, K., Gui, Z., Li, Z., Huang, Q., & Li, R.~Adopting cloud computing to optimize spatial web portals for better performance to support Digital Earth and other global geospatial initiatives~International Journal of Digital Earth~8~2015~451~~~0~ ~0~ ~21/12/2018 14:55:40.100000000\n",
      "X..................\n",
      "[warn]: crossref API sent code = 400\n",
      "\t- input: Shruti Daggumati, Igor Soares, Jieting Wu, David Cao, Hongfeng Yu, Jun Wang~Tweether: A Visualization Tool Displaying Correlation of Weather to Tweets~IS&T Conference on Visualization and Data Analysis (VDA?16)~~2016~~~url:http://www.ingentaconnect.com/content/ist/ei/2016/00002016/00000001/art00022~0~ ~0~ ~01/09/2016 20:47:57.796000000\n",
      "X.................XX.....XXX........................XX....................X..............................................X.........................X.................\n",
      "CPU times: total: 25.9 s\n",
      "Wall time: 35min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "NOTE: THIS IS LIVE DATA AND REQUIRES RELOADING IF THE LATEST DATA IS NECESSARY.  \n",
    "EXPECT THIS CELL TO RUN FOR SOME TIME (~25-40min).\n",
    "'''\n",
    "\n",
    "# get the cites AND cr_meta for all the data\n",
    "for k in id_map.keys():\n",
    "    header = { \"Accept\": \"application/vnd.citationstyles.csl+json\" }\n",
    "    for i in id_map[k]:\n",
    "        if i['doi'].strip():\n",
    "            doi = i['doi'].strip() \n",
    "            cr_meta = get_metadata(doi)\n",
    "            \n",
    "            if cr_meta:\n",
    "                try:\n",
    "                    i['cites'] = cr_meta['is-referenced-by-count']\n",
    "                except:\n",
    "                    i['cites'] = -1\n",
    "\n",
    "                i['cr_meta'] = cr_meta\n",
    "                i['ams_bib'] = get_bib_citation(doi).decode('utf-8')\n",
    "                \n",
    "                print(\".\", end=\"\")\n",
    "                time.sleep(BE_NICE)\n",
    "        else:\n",
    "            doi, cites, cr_meta = get_doi_bib_lookup(i['citation'])\n",
    "            if doi:\n",
    "                i['doi'], i['cites'] = doi, cites\n",
    "                i['cr_meta'] = cr_meta\n",
    "                i['ams_bib'] = get_bib_citation(doi).decode('utf-8')\n",
    "\n",
    "                print(\".\", end=\"\")\n",
    "            else:\n",
    "                print(\"X\", end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7509eaf-4193-435e-b512-0970b19cde14",
   "metadata": {},
   "source": [
    "## STORE FINAL DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061015d-0b08-472a-96ba-56c9ce9921cc",
   "metadata": {},
   "source": [
    "Final output file \n",
    "\n",
    "* [`outputs/nsf/nsf_mapping.json`](/outputs/nsf/nsf_mapping.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c3741c8-46d9-4e5a-a1d3-5454a632f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/nsf/nsf_mapping.json\", \"w\") as fo:\n",
    "    json.dump(id_map, fo, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91985933-043a-41df-9a64-10960e6473db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b290385-12f6-4105-8fed-1af2f9c085db",
   "metadata": {},
   "source": [
    "### TODO: DELETE ALL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bd56f-a2da-4e08-804c-57e03459f58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e6588-7e65-4f39-a885-1e5338abafd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1d6d6-d439-4209-b7e2-e8b22c56e968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daace5ff-bc78-4c3a-a5b8-983da360b7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b327fbcd-fbb2-4d40-b8f6-ea54a344c972",
   "metadata": {},
   "source": [
    "### GET CITATIONS FOR ALL FOUND DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c14c17-9bfa-4a9d-a706-1eb6c01bf34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1f54b-1671-4174-ac87-742fffc58222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c7eb1cc-669f-422c-9edf-b938d0c723ab",
   "metadata": {},
   "source": [
    "Now that we have crucial data, we will store an [AMS style citation](https://www.ametsoc.org/index.cfm/ams/publications/author-information/formatting-and-manuscript-components/references/) along with the metadata from crossref."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb3c7a-47dd-4a14-8d17-29bf7578d71c",
   "metadata": {},
   "source": [
    "**For convenience, we  dump all NSF ID, DOI and citation counts to:**:\n",
    "\n",
    "* FILE [`outputs/citations.tsv`](/outputs/citations.tsv) (DUPLICATES INCLUDED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7dbacdf-5666-495b-9e7a-b68c2a196530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVED TO 00g_full_data_mapping.ipynb\n",
    "\n",
    "# '''\n",
    "# THIS LOADS THE DATA STORED FROM THE FILE IN THE PREVIOUSLY \n",
    "# EXECUTED CELL\n",
    "# '''\n",
    "\n",
    "# from datetime import datetime\n",
    "# import json\n",
    "# # datetime.now().strftime('%Y%d%m_%H%M%S')}\n",
    "# f = json.load(open(\"../outputs/nsf/nsf_mapping.json\"))\n",
    "# with open(f\"../outputs/citations.tsv\", \"w\", encoding='utf-8') as fo:\n",
    "#     for k in f.keys():\n",
    "#         for c in f[k]:\n",
    "#             if c['doi']:\n",
    "#                 if c['ams_bib'] and c['ams_bib'][:5] != '<!DOC':\n",
    "#                     fo.write(f\"{k}\\t{c['doi']}\\t{c['cites']}\\n\") \n",
    "#                     print(\".\", end=\"\")\n",
    "#                 else:\n",
    "#                     fo.write(f\"{k}\\t{c['doi']}\\t-1\\n\")\n",
    "#                     print(\".\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
